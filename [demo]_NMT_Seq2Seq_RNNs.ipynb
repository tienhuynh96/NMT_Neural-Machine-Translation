{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16542ba1cddd44a588876709b2d7942f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_463d53d194954809b3c2011c0c07c6bf",
              "IPY_MODEL_353e0b411731471cba6694ad9154eca6",
              "IPY_MODEL_1379d78bfa6f4ecfbae4b45a1249e265"
            ],
            "layout": "IPY_MODEL_43d07ad22b69437a893122f067b5d988"
          }
        },
        "463d53d194954809b3c2011c0c07c6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df3f71947ad435c87816bcdd60855d7",
            "placeholder": "​",
            "style": "IPY_MODEL_da997de6bbed452d813e2bd0d69f4b8b",
            "value": "Downloading builder script: 100%"
          }
        },
        "353e0b411731471cba6694ad9154eca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ed8aed9a91450a870451f9d4016fb1",
            "max": 5158,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93b6bfc5eda9467fb6157f21195be17b",
            "value": 5158
          }
        },
        "1379d78bfa6f4ecfbae4b45a1249e265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5681251dfbf49b980b4a2580dcf9652",
            "placeholder": "​",
            "style": "IPY_MODEL_d1dbb915ce0f469c84f8f21e40d1a6d7",
            "value": " 5.16k/5.16k [00:00&lt;00:00, 207kB/s]"
          }
        },
        "43d07ad22b69437a893122f067b5d988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df3f71947ad435c87816bcdd60855d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da997de6bbed452d813e2bd0d69f4b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45ed8aed9a91450a870451f9d4016fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b6bfc5eda9467fb6157f21195be17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5681251dfbf49b980b4a2580dcf9652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1dbb915ce0f469c84f8f21e40d1a6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "020a91257a1d4cdcba47a77022bc267d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a2420bf4a444d90af464d66a1a70215",
              "IPY_MODEL_aa2d67e2a0324408b0ec5ae9f94dbabd",
              "IPY_MODEL_64fcc2b5f11d4e7d8d0fd6c3001d7523"
            ],
            "layout": "IPY_MODEL_6579a22688cc4a57b0f8e02e40e5a339"
          }
        },
        "9a2420bf4a444d90af464d66a1a70215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1947029a2a65499b9e61e11a3828eefe",
            "placeholder": "​",
            "style": "IPY_MODEL_0d80b1a5ca7c48eaa4679407505c4aae",
            "value": "Downloading readme: 100%"
          }
        },
        "aa2d67e2a0324408b0ec5ae9f94dbabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97f4786458574f049953bd85b994c325",
            "max": 4897,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35efcc271b0145f0996ab19bbe9c7478",
            "value": 4897
          }
        },
        "64fcc2b5f11d4e7d8d0fd6c3001d7523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8423e90e54c4f3195c84f4251022077",
            "placeholder": "​",
            "style": "IPY_MODEL_dcb71c1d35f64c1d8698ddba3c602da4",
            "value": " 4.90k/4.90k [00:00&lt;00:00, 244kB/s]"
          }
        },
        "6579a22688cc4a57b0f8e02e40e5a339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1947029a2a65499b9e61e11a3828eefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d80b1a5ca7c48eaa4679407505c4aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97f4786458574f049953bd85b994c325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35efcc271b0145f0996ab19bbe9c7478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8423e90e54c4f3195c84f4251022077": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb71c1d35f64c1d8698ddba3c602da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tienhuynh96/NMT_Neural-Machine-Translation/blob/main/%5Bdemo%5D_NMT_Seq2Seq_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Machine Translation using RNNs**"
      ],
      "metadata": {
        "id": "ic0MvWoNA0HJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Dataset**"
      ],
      "metadata": {
        "id": "i-Wp-wD1A6eD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uS94DWsqlxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbc6862-607e-48e0-9d5c-958a9866570a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1.1 Load dataset from dataset library**\n",
        "\n",
        "The IWSLT'15 English-Vietnamese data is used from Stanford NLP group."
      ],
      "metadata": {
        "id": "LqpZ11aOfiQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "# The IWSLT'15 English-Vietnamese data is used from Stanford NLP group.\n",
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(\n",
        "    \"mt_eng_vietnamese\",\n",
        "    \"iwslt2015-en-vi\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "16542ba1cddd44a588876709b2d7942f",
            "463d53d194954809b3c2011c0c07c6bf",
            "353e0b411731471cba6694ad9154eca6",
            "1379d78bfa6f4ecfbae4b45a1249e265",
            "43d07ad22b69437a893122f067b5d988",
            "2df3f71947ad435c87816bcdd60855d7",
            "da997de6bbed452d813e2bd0d69f4b8b",
            "45ed8aed9a91450a870451f9d4016fb1",
            "93b6bfc5eda9467fb6157f21195be17b",
            "e5681251dfbf49b980b4a2580dcf9652",
            "d1dbb915ce0f469c84f8f21e40d1a6d7",
            "020a91257a1d4cdcba47a77022bc267d",
            "9a2420bf4a444d90af464d66a1a70215",
            "aa2d67e2a0324408b0ec5ae9f94dbabd",
            "64fcc2b5f11d4e7d8d0fd6c3001d7523",
            "6579a22688cc4a57b0f8e02e40e5a339",
            "1947029a2a65499b9e61e11a3828eefe",
            "0d80b1a5ca7c48eaa4679407505c4aae",
            "97f4786458574f049953bd85b994c325",
            "35efcc271b0145f0996ab19bbe9c7478",
            "a8423e90e54c4f3195c84f4251022077",
            "dcb71c1d35f64c1d8698ddba3c602da4"
          ]
        },
        "id": "kE8QfnmRem2u",
        "outputId": "2f5e4b8e-dbbc-4dff-d2fb-dd248b95d917",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for mt_eng_vietnamese contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mt_eng_vietnamese\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16542ba1cddd44a588876709b2d7942f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/4.90k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "020a91257a1d4cdcba47a77022bc267d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "Couldn't reach https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en (error 403)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-09688822f0cc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m data = load_dataset(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"mt_eng_vietnamese\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"iwslt2015-en-vi\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2608\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2609\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   2610\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                             \u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_proc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_proc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m                         self._download_and_prepare(\n\u001b[0m\u001b[1;32m   1028\u001b[0m                             \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m                             \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_download_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_splits_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m         super()._download_and_prepare(\n\u001b[0m\u001b[1;32m   1790\u001b[0m             \u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0msplit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSplitDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0msplit_generators_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_split_generators_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         \u001b[0msplit_generators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msplit_generators_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;31m# Checksums verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/mt_eng_vietnamese/53add551a01e9874588066f89d42925f9fad43db347199dad00f7e4b0c905a71/mt_eng_vietnamese.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mdl_dir_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DATA_URL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tst2013\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mdl_dir_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DATA_URL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mdl_dir_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DATA_URL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload_and_extract\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mextracted_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \"\"\"\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_recorded_sizes_checksums\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstack_multiprocessing_download_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             downloaded_path_or_paths = map_nested(\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0mdownload_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0murl_or_urls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mdata_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_batched\u001b[0;34m(self, url_or_filenames, download_config)\u001b[0m\n\u001b[1;32m    311\u001b[0m             )\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    314\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             return [\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0murl_or_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl_or_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/download/download_manager.py\u001b[0m in \u001b[0;36m_download_single\u001b[0;34m(self, url_or_filename, download_config)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# append the relative path to the base_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0murl_or_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_or_path_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_origin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, download_config, **download_kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_remote_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, use_auth_token, ignore_url_params, storage_options, download_desc, disable_tqdm)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't reach {url} ({repr(head_error)})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't reach {url} (error {response.status_code})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't reach {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: Couldn't reach https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en (error 403)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train']"
      ],
      "metadata": {
        "id": "MaNRvzE2gERN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['train']['translation'][0]"
      ],
      "metadata": {
        "id": "6dKIVflogEJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1.2 Incase can not load dataset from dataset**\n",
        "\n",
        "Wget data from github: https://github.com/stefan-it/nmt-en-vi"
      ],
      "metadata": {
        "id": "NaG0p875f5jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incase can not load dataset from dataset\n",
        "# Try\n",
        "# Wget data from github: https://github.com/stefan-it/nmt-en-vi\n",
        "# Train file\n",
        "!wget \"https://github.com/stefan-it/nmt-en-vi/raw/master/data/train-en-vi.tgz\"\n",
        "# Dev file\n",
        "!wget \"https://github.com/stefan-it/nmt-en-vi/raw/master/data/dev-2012-en-vi.tgz\"\n",
        "# Test file\n",
        "!wget \"https://github.com/stefan-it/nmt-en-vi/raw/master/data/test-2013-en-vi.tgz\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKR74vR4DfBt",
        "outputId": "47c9e1be-fdbf-4c29-c69e-0dea771bfcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-29 02:28:55--  https://github.com/stefan-it/nmt-en-vi/raw/master/data/train-en-vi.tgz\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/stefan-it/nmt-en-vi/master/data/train-en-vi.tgz [following]\n",
            "--2024-05-29 02:28:56--  https://raw.githubusercontent.com/stefan-it/nmt-en-vi/master/data/train-en-vi.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9903559 (9.4M) [application/octet-stream]\n",
            "Saving to: ‘train-en-vi.tgz’\n",
            "\n",
            "train-en-vi.tgz     100%[===================>]   9.44M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2024-05-29 02:28:58 (130 MB/s) - ‘train-en-vi.tgz’ saved [9903559/9903559]\n",
            "\n",
            "--2024-05-29 02:28:58--  https://github.com/stefan-it/nmt-en-vi/raw/master/data/dev-2012-en-vi.tgz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/stefan-it/nmt-en-vi/master/data/dev-2012-en-vi.tgz [following]\n",
            "--2024-05-29 02:28:58--  https://raw.githubusercontent.com/stefan-it/nmt-en-vi/master/data/dev-2012-en-vi.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103520 (101K) [application/octet-stream]\n",
            "Saving to: ‘dev-2012-en-vi.tgz’\n",
            "\n",
            "dev-2012-en-vi.tgz  100%[===================>] 101.09K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-05-29 02:28:59 (6.99 MB/s) - ‘dev-2012-en-vi.tgz’ saved [103520/103520]\n",
            "\n",
            "--2024-05-29 02:28:59--  https://github.com/stefan-it/nmt-en-vi/raw/master/data/test-2013-en-vi.tgz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/stefan-it/nmt-en-vi/master/data/test-2013-en-vi.tgz [following]\n",
            "--2024-05-29 02:28:59--  https://raw.githubusercontent.com/stefan-it/nmt-en-vi/master/data/test-2013-en-vi.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102940 (101K) [application/octet-stream]\n",
            "Saving to: ‘test-2013-en-vi.tgz’\n",
            "\n",
            "test-2013-en-vi.tgz 100%[===================>] 100.53K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-05-29 02:28:59 (5.62 MB/s) - ‘test-2013-en-vi.tgz’ saved [102940/102940]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the tgz file\n",
        "!tar -xzf train-en-vi.tgz\n",
        "!tar -xzf dev-2012-en-vi.tgz\n",
        "!tar -xzf test-2013-en-vi.tgz"
      ],
      "metadata": {
        "id": "AEPeBIINEDR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset shape similar with datashape which download from datasets library\n",
        "data = {\n",
        "    \"train\": {\n",
        "                \"translation\":[]\n",
        "              },\n",
        "    \"validation\": {\n",
        "                \"translation\":[]\n",
        "              },\n",
        "    \"test\": {\n",
        "                \"translation\":[]\n",
        "              },\n",
        "}"
      ],
      "metadata": {
        "id": "-4V3Q_Sez0w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTnEq8bXz8vF",
        "outputId": "1c145b81-9732-4a48-b152-373f58b06a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': {'translation': []},\n",
              " 'validation': {'translation': []},\n",
              " 'test': {'translation': []}}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add path for train, test, validation file\n",
        "# Train file\n",
        "train_source_file = \"/content/train.en\"\n",
        "train_target_file = \"/content/train.vi\"\n",
        "# Validation file\n",
        "val_source_file = \"/content/tst2012.en\"\n",
        "val_target_file = \"/content/tst2012.vi\"\n",
        "# Test file\n",
        "test_source_file = \"/content/tst2013.en\"\n",
        "test_target_file = \"/content/tst2013.vi\""
      ],
      "metadata": {
        "id": "2BHHwd_vLUP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build function: Get examples from sourse, target file and append into data\n",
        "def generate_examples(source_file, target_file, data, dataname):\n",
        "    # Open and read source file and target file of \"train, test, validation\" data\n",
        "    with open(source_file, encoding=\"utf-8\") as f:\n",
        "        source_sentences = f.read().split(\"\\n\")\n",
        "    with open(target_file, encoding=\"utf-8\") as f:\n",
        "        target_sentences = f.read().split(\"\\n\")\n",
        "\n",
        "    # Add examples of \"train, test, validation\" data\n",
        "    data_gen = data[dataname]['translation']\n",
        "    source, target = \"en\", \"vi\"\n",
        "    for idx, (l1, l2) in enumerate(zip(source_sentences, target_sentences)):\n",
        "        result = {source: l1, target: l2}\n",
        "        data_gen.append(result)\n",
        "    return data"
      ],
      "metadata": {
        "id": "euGEtz6HhnZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = generate_examples(source_file=train_source_file, target_file=train_target_file,\n",
        "                        data=data, dataname=\"train\")\n",
        "\n",
        "data = generate_examples(test_source_file, test_target_file, data, \"test\")\n",
        "data = generate_examples(val_source_file, val_target_file, data, \"validation\")\n"
      ],
      "metadata": {
        "id": "KYn31z2LzoZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['train']['translation'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Pb-VDdLT9s",
        "outputId": "2b31f3e4-a467-4e23-dbaa-b6e68e792e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Rachel Pike : The science behind a climate headline',\n",
              " 'vi': 'Khoa học đằng sau một tiêu đề về khí hậu'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['test']['translation'][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfrGNPHgsZ0q",
        "outputId": "8f8d140a-5351-453e-dd9d-6a51deeb10aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'When I was little , I thought my country was the best on the planet , and I grew up singing a song called &quot; Nothing To Envy . &quot;',\n",
              " 'vi': 'Khi tôi còn nhỏ , Tôi nghĩ rằng BắcTriều Tiên là đất nước tốt nhất trên thế giới và tôi thường hát bài &quot; Chúng ta chẳng có gì phải ghen tị . &quot;'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['validation']['translation'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3dNuG7EBCjY",
        "outputId": "fb2416ce-8778-4e58-ccf7-4e53f5cd0d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'How can I speak in 10 minutes about the bonds of women over three generations , about how the astonishing strength of those bonds took hold in the life of a four-year-old girl huddled with her young sister , her mother and her grandmother for five days and nights in a small boat in the China Sea more than 30 years ago , bonds that took hold in the life of that small girl and never let go -- that small girl now living in San Francisco and speaking to you today ?',\n",
              " 'vi': 'Làm sao tôi có thể trình bày trong 10 phút về sợi dây liên kết những người phụ nữ qua ba thế hệ , về việc làm thế nào những sợi dây mạnh mẽ đáng kinh ngạc ấy đã níu chặt lấy cuộc sống của một cô bé bốn tuổi co quắp với đứa em gái nhỏ của cô bé , với mẹ và bà trong suốt năm ngày đêm trên con thuyền nhỏ lênh đênh trên Biển Đông hơn 30 năm trước , những sợi dây liên kết đã níu lấy cuộc đời cô bé ấy và không bao giờ rời đi -- cô bé ấy giờ sống ở San Francisco và đang nói chuyện với các bạn hôm nay ?'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tokenization**"
      ],
      "metadata": {
        "id": "zezwqsDPBHbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get_tokenizer and build vocab\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "2rln4Fc8ICSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655af16b-f395-42c1-f0c4-a8c301f681dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set source and target language\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'vi'\n",
        "\n",
        "# Create token_transform and vocab_transform is empty dictionary\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "# Add tokenizer for source and target language\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('basic_english')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('basic_english')\n",
        "\n",
        "# Set special symbols and its id\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>','eos']\n"
      ],
      "metadata": {
        "id": "0gaIkhLCICP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS7FxpR2ICNP",
        "outputId": "90f12076-a8e2-4968-953e-973fcec657f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': <function torchtext.data.utils._basic_english_normalize(line)>,\n",
              " 'vi': <function torchtext.data.utils._basic_english_normalize(line)>}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab\n",
        "# Build yield tokens function: input data_iter and language (en or vi)\n",
        "def yield_tokens(data_iter, lang):\n",
        "  for data_sample in data_iter['translation']:\n",
        "    yield token_transform[lang](data_sample[lang])\n",
        "\n",
        "# Build vocab for source and target language\n",
        "for lang in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  # Get data from train data\n",
        "  train_iter = data['train']\n",
        "\n",
        "  # Create torchtext's vocab object\n",
        "  vocab_transform[lang] = build_vocab_from_iterator(\n",
        "      yield_tokens(train_iter, lang),   # yield for each language\n",
        "      min_freq=1,               # Minimum of appear tokens in vocab is stored\n",
        "      specials=special_symbols, # Get special symbols\n",
        "      special_first=True        # Set special symbol ids is first\n",
        "  )\n",
        "\n",
        "  # Set set_default_index is UNK_IDX\n",
        "  vocab_transform[lang].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "0ZyylGGoICK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab for source language\n",
        "vocab_transform[SRC_LANGUAGE].get_itos()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7Bi84QLICH9",
        "outputId": "255ddb04-faff-4ab1-ae83-4fe4620e4910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<bos>', 'eos', ',', '.', 'the', 'and', 'to', '&apos']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocab for target language\n",
        "vocab_transform[TGT_LANGUAGE].get_itos()[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CObA65eFICFn",
        "outputId": "0fc3ae6f-4aaa-4088-bce3-d96f3dc290b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<bos>', 'eos', ',', '.', 'và', 'tôi', 'là', 'một']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_transform[SRC_LANGUAGE]), len(vocab_transform[TGT_LANGUAGE])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptdBDOQyNgLc",
        "outputId": "414dfa78-a16f-4cd5-817e-2a3cdeed4246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47270, 21113)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Dataloader**"
      ],
      "metadata": {
        "id": "aiKbMbtVBLCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence     # padding follow the highest sequence length in dataset\n",
        "\n",
        "# Set max len\n",
        "MAX_LEN = 100\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "# Take a series of transformation functions as arguments and returns a new function\n",
        "def sequential_transforms(*transforms):   # *transforms allows the function to accept any number of transformation functions as arguments.\n",
        "    def func(txt_input): # inner function\n",
        "        # Applying Transformations in Sequence\n",
        "        # For each transformation, it applies the function to txt_input, updating txt_input with the transformed result.\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices: BOS-ids-EOS\n",
        "def tensor_transform(token_ids):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# Function to truncate\n",
        "def truncate(sample):\n",
        "    if sample.size(0) > MAX_LEN:\n",
        "        return sample[:MAX_LEN, :]\n",
        "    else:\n",
        "        return sample\n",
        "\n"
      ],
      "metadata": {
        "id": "vTX40fEM3OhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for lang in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[lang] = sequential_transforms(\n",
        "        token_transform[lang], # Tokenization   => tokens\n",
        "        vocab_transform[lang], # Numericalization => ids\n",
        "        tensor_transform # Add BOS/EOS and create tensor  => bos ids eos\n",
        "    )\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    # transforms for each sample in batch\n",
        "    for sample in batch:\n",
        "        src_sample, tgt_sample = sample[SRC_LANGUAGE], sample[TGT_LANGUAGE]\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample).to(dtype=torch.int64))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample).to(dtype=torch.int64))\n",
        "\n",
        "    # Add pad sequence and truncate\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    src_batch = truncate(src_batch)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "    tgt_batch = truncate(tgt_batch)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "noTtkhOnr6VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Build dataloader for train, validation, test data\n",
        "train_dataloader = DataLoader(\n",
        "    data['train']['translation'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    data['validation']['translation'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    data['test']['translation'],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ],
      "metadata": {
        "id": "Xj48YRZs8-NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the data of first batch\n",
        "src_ids, tgt_ids = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "gU_0n__gZiSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape\n",
        "src_ids.shape, tgt_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hS46ds80poj",
        "outputId": "0f766fdb-e177-4607-d337-eff177cf9e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 52]), torch.Size([32, 78]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbFeQSvb4IMw",
        "outputId": "ff91f905-59d3-4cb8-8102-1a0aaa600f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,  6429, 17576,     6,   295,   553,    11,   682,  5334,     3,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the source ids\n",
        "' '.join([vocab_transform[SRC_LANGUAGE].lookup_token(token) for token in src_ids[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "M1SlbzvI4UtQ",
        "outputId": "1f7af4ff-f9a3-47f7-9916-1f68e89b1f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<bos> rachel pike the science behind a climate headline eos <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the target ids\n",
        "' '.join([vocab_transform[TGT_LANGUAGE].lookup_token(token) for token in tgt_ids[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "O0_ZeXFM4s1u",
        "outputId": "04da6917-69b3-472c-e681-4bcac084cc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<bos> khoa học đằng sau một tiêu đề về khí hậu eos <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model**"
      ],
      "metadata": {
        "id": "Tv79ODxTBOcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.1 Build encoder**"
      ],
      "metadata": {
        "id": "f3q32cEzw1Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build encoder fucntion\n",
        "import torch.nn as nn\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size        # hidden size of RNN\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)        # Covert to embedding\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True) # Use GRU\n",
        "        self.dropout = nn.Dropout(dropout_p)  # Dropout\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))  # b x s x h\n",
        "        output, hidden = self.gru(embedded)             # output: b x s x h and hidden:number layer x b x h\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "by_JLG9NdCHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set encoder\n",
        "input_size = len(vocab_transform[SRC_LANGUAGE])\n",
        "hidden_size = 256\n",
        "\n",
        "encoder = EncoderRNN(input_size, hidden_size)"
      ],
      "metadata": {
        "id": "J4_-I-BWiHVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check encoder function\n",
        "encoder_output, encoder_hidden = encoder(src_ids)\n",
        "encoder_output.shape, encoder_hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvHHaO-LiVr4",
        "outputId": "b2571f1e-c9e4-4a74-f04b-b4f705c560e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 52, 256]), torch.Size([1, 32, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.2 Build Decoder**"
      ],
      "metadata": {
        "id": "X-W-GNIhw6LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Decoder fucntion\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)          # Output of decoder\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input)            # input: target sentence\n",
        "        output, hidden = self.gru(output, hidden) # output: b x s x h and hidden:number layer x b x h\n",
        "        output = self.out(output)                 # compute liner for each sequence (s) in output\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "yKCMqt3Sd4gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Decoder\n",
        "output_size = len(vocab_transform[TGT_LANGUAGE])\n",
        "hidden_size = 256\n",
        "\n",
        "decoder = DecoderRNN(hidden_size, output_size)"
      ],
      "metadata": {
        "id": "bi3ylkwByYKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Decoder function\n",
        "decoder_output, decoder_hidden = decoder(tgt_ids, encoder_hidden)\n",
        "decoder_output.shape, decoder_hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK8n5wJWy4Et",
        "outputId": "d6223a4f-9b0b-4eaf-c08d-d6fcd9ac6747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 78, 21113]), torch.Size([1, 32, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = torch.empty(32, 1, dtype=torch.long).fill_(BOS_IDX)"
      ],
      "metadata": {
        "id": "ZCkYVxzyAvwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nWpVfkuRBThp",
        "outputId": "67f33c47-ba42-4b52-f861-ee106cc7db90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2],\n",
              "        [2]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.3 Build sequence to sequence function**"
      ],
      "metadata": {
        "id": "kg9YFJG6yZmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build sequence to sequence fucntion\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device, BOS_IDX):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        self.BOS_IDX = BOS_IDX\n",
        "\n",
        "    def forward(self, src_ids, tgt_ids):\n",
        "        # Get batch size\n",
        "        batch_size = tgt_ids.size(0)\n",
        "        # Get sequence length\n",
        "        seq_len = tgt_ids.size(1)\n",
        "\n",
        "        # Create decoder input (Batch size, 1), each input begin by BOS_IDS\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=self.device).fill_(self.BOS_IDX)\n",
        "        # Compute encoder ouput and encoder hidden (encoder hidden = decoder hidden)\n",
        "        encoder_output, decoder_hidden = self.encoder(src_ids)\n",
        "        # Create empty list of  decoder output\n",
        "        decoder_outputs = []\n",
        "\n",
        "        # Iterator each token in target sentence\n",
        "        for i in range(seq_len):\n",
        "            # Compute decoder output and update decoder_hidden\n",
        "            decoder_output, decoder_hidden  = self.decoder(decoder_input, decoder_hidden)     # output: b x s x h and hidden:number layer x b x h\n",
        "            # Update decoder output\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            # Teacher forcing: Feed the target as the next input\n",
        "            decoder_input = tgt_ids[:, i].unsqueeze(1) # Teacher forcing, unsqueeze(1) to get shape (batct, 1)\n",
        "\n",
        "        # Cat the decoder ouputs\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)   # concatenate at sequence dimention, decoder_outputs is list => use torch.cat to concatenate\n",
        "        return decoder_outputs, decoder_hidden"
      ],
      "metadata": {
        "id": "aggH_x52ktOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "input_size = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_size = len(vocab_transform[TGT_LANGUAGE])\n",
        "hidden_size = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Build encoder\n",
        "encoder = EncoderRNN(input_size, hidden_size)\n",
        "# Build decoder\n",
        "decoder = DecoderRNN(hidden_size, output_size)\n",
        "# Build model = sequence to sequence\n",
        "model = Seq2Seq(encoder, decoder, device, EOS_IDX)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXFfjyo7tSgf",
        "outputId": "821401db-9911-497f-b6e8-e4826724aeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): EncoderRNN(\n",
              "    (embedding): Embedding(47270, 256)\n",
              "    (gru): GRU(256, 256, batch_first=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): DecoderRNN(\n",
              "    (embedding): Embedding(21113, 256)\n",
              "    (gru): GRU(256, 256, batch_first=True)\n",
              "    (out): Linear(in_features=256, out_features=21113, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target input is sequence except the last token\n",
        "tgt_input = tgt_ids[:, :-1]\n",
        "# Target ouput is sequence except the first token (BOS)\n",
        "tgt_output = tgt_ids[:, 1:]\n",
        "\n",
        "# Compute decoder_outputs, decoder_hidden of model\n",
        "decoder_outputs, decoder_hidden = model(src_ids.to(device), tgt_input.to(device))"
      ],
      "metadata": {
        "id": "F5wYkh6LeDxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape\n",
        "decoder_outputs.shape, decoder_hidden.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygvrsy96eGIM",
        "outputId": "d2eb8799-0a30-48e2-a6ba-40eaf0161e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 77, 21113]), torch.Size([1, 32, 256]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52flF7tIuFP-",
        "outputId": "f18ecb69-c52c-4d61-c877-5199bfa3c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 77])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss = Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "metadata": {
        "id": "ykLF7dDeuNJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape decoder_outputs = (Batch_size * Sequence length, hidden)\n",
        "decoder_outputs.reshape(-1, decoder_outputs.shape[-1]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCtJb4x4upu3",
        "outputId": "4693127b-8eb2-4e92-8d26-a68d093668a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2464, 21113])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape tgt_output = (Batch_size * Sequence length, 1)\n",
        "tgt_output.reshape(-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atf1y2Cwur3e",
        "outputId": "28217bb1-a2ce-48c1-d738-50ad8b5f1727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2464])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute loss\n",
        "loss = criterion(decoder_outputs.reshape(-1, decoder_outputs.shape[-1]), tgt_output.reshape(-1).to(device))\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoB8HdipuN5o",
        "outputId": "93567371-bb07-4536-f32b-cf293312bc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.9645, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Trainer**"
      ],
      "metadata": {
        "id": "hzudM9B3BQyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Creaete train epoch function\n",
        "def train_epoch(model, optimizer, criterion, train_dataloader, device):\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    # Iterator to get data from train_loader\n",
        "    for idx, (src_ids, tgt_ids) in enumerate(train_dataloader):\n",
        "        # put src_ids, tgt_ids to device\n",
        "        src_ids = src_ids.to(device)\n",
        "        tgt_ids = tgt_ids.to(device)\n",
        "\n",
        "        # Get input and output target\n",
        "        tgt_input = tgt_ids[:, :-1]\n",
        "        tgt_output = tgt_ids[:, 1:]\n",
        "\n",
        "        # Set optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # Compute decoder_outputs, decoder_hidden\n",
        "        decoder_outputs, decoder_hidden = model(src_ids, tgt_input)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(\n",
        "            decoder_outputs.reshape(-1, decoder_outputs.shape[-1]),\n",
        "            tgt_output.reshape(-1))\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # weight update\n",
        "        optimizer.step()\n",
        "        # Append loss\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return sum(losses) / len(losses)\n",
        "\n",
        "# Creaete evaluate epoch function\n",
        "def evaluate(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    with torch.no_grad():\n",
        "        for idx, (src_ids, tgt_ids) in enumerate(data_loader):\n",
        "            # put src_ids, tgt_ids to device\n",
        "            src_ids = src_ids.to(device)\n",
        "            tgt_ids = tgt_ids.to(device)\n",
        "            # Get input and output target\n",
        "            tgt_input = tgt_ids[:, :-1]\n",
        "            tgt_output = tgt_ids[:, 1:]\n",
        "\n",
        "            # Compute decoder_outputs, decoder_hidden\n",
        "            decoder_outputs, decoder_hidden = model(src_ids, tgt_input)\n",
        "            loss = criterion(\n",
        "                decoder_outputs.reshape(-1, decoder_outputs.shape[-1]),\n",
        "                tgt_output.reshape(-1)\n",
        "            )\n",
        "            # Append loss\n",
        "            losses.append(loss.item())\n",
        "    return sum(losses) / len(losses)\n",
        "\n",
        "# Creaete train function\n",
        "def train(model, train_dataloader, valid_dataloader, optimizer, criterion, device, epochs):\n",
        "    # Iterator for each epoch\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # Set start time\n",
        "        start_time = time.time()\n",
        "        # Compute train loss\n",
        "        train_loss = train_epoch(model, optimizer, criterion, train_dataloader, device)\n",
        "        # Compute validatioin loss\n",
        "        valid_loss = evaluate(model, valid_dataloader, criterion, device)\n",
        "        # Set end time\n",
        "        end_time = time.time()\n",
        "        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {valid_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ],
      "metadata": {
        "id": "Q0NxKwpIBS7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Training**"
      ],
      "metadata": {
        "id": "2duk3dBAyVzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Create parameter input\n",
        "input_size = len(vocab_transform[SRC_LANGUAGE])\n",
        "output_size = len(vocab_transform[TGT_LANGUAGE])\n",
        "hidden_size = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create encoder and decoder\n",
        "encoder = EncoderRNN(input_size, hidden_size)\n",
        "decoder = DecoderRNN(hidden_size, output_size)\n",
        "# Create model\n",
        "model = Seq2Seq(encoder, decoder, device, EOS_IDX)\n",
        "model.to(device)\n",
        "\n",
        "# Set optimizer, loss and epochs\n",
        "epochs = 10\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "# Train model\n",
        "train(model, train_dataloader, valid_dataloader, optimizer, criterion, device, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw66lVTda2Dt",
        "outputId": "465a7697-4db1-45ae-8f23-2664005ee6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 5.521, Val loss: 5.186, Epoch time = 550.014s\n",
            "Epoch: 2, Train loss: 5.001, Val loss: 5.023, Epoch time = 547.630s\n",
            "Epoch: 3, Train loss: 4.779, Val loss: 4.960, Epoch time = 549.021s\n",
            "Epoch: 4, Train loss: 4.630, Val loss: 4.935, Epoch time = 547.652s\n",
            "Epoch: 5, Train loss: 4.518, Val loss: 4.932, Epoch time = 546.922s\n",
            "Epoch: 6, Train loss: 4.428, Val loss: 4.910, Epoch time = 545.556s\n",
            "Epoch: 7, Train loss: 4.354, Val loss: 4.918, Epoch time = 547.581s\n",
            "Epoch: 8, Train loss: 4.291, Val loss: 4.935, Epoch time = 547.704s\n",
            "Epoch: 9, Train loss: 4.238, Val loss: 4.941, Epoch time = 550.145s\n",
            "Epoch: 10, Train loss: 4.191, Val loss: 4.953, Epoch time = 549.088s\n"
          ]
        }
      ]
    }
  ]
}